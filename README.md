# üìù Fine-Tuning Hugging Face Model on Custom Dataset

–ü—Ä–∏–≤–µ—Ç! üëã  
–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è **fine-tuning –º–æ–¥–µ–ª–∏ Hugging Face** –Ω–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å –∏—Ö —Ç–µ–º–∞–º–∏. –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å ‚Äî –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å **–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º** –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Å Lenta.ru. üì∞

---

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

- **data/**  
  üìë –î–∞—Ç–∞—Å–µ—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∏—Ö —Ç–µ–º–∞–º–∏, —Å–æ–±—Ä–∞–Ω–Ω—ã–º–∏ —Å Lenta.ru.  

- **logging_config/**  
  üõ†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã —É–¥–æ–±–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.  

- **model/**  
  ü§ñ –ì–æ—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å Hugging Face –∏ –Ω–æ—É—Ç–±—É–∫ –¥–ª—è fine-tuning.  

- **parsing/**  
  üîç –°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –æ–±—É—á–µ–Ω–∏—é.  

---

## ü§ñ –ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä

### –ú–æ–¥–µ–ª—å: `BertForSequenceClassification`

- –ë–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ **`DeepPavlov/rubert-base-cased`**  
- –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤** (–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π)  
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: **3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏**  
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å Hugging Face `Trainer` –¥–ª—è fine-tuning  

–ü—Ä–∏–º–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏:  

```python
from transformers import BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained(
    "DeepPavlov/rubert-base-cased",
    num_labels=3  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
)
```
### –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä: `BertTokenizerFast`

- –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ç–æ–π –∂–µ –º–æ–¥–µ–ª–∏ **`DeepPavlov/rubert-base-cased`**
- –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç **—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ —á–∏—Å–ª–æ–≤—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã**, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–Ω–∏–º–∞–µ—Ç –º–æ–¥–µ–ª—å
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç fast-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é —Å –ø–∞–¥–¥–∏–Ω–≥–æ–º –∏ –º–∞—Å–∫–∏–Ω–≥–æ–º

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞:
```python
from transformers import BertTokenizerFast

tokenizer = BertTokenizerFast.from_pretrained("DeepPavlov/rubert-base-cased")

inputs = tokenizer(
    "–ü—Ä–∏–º–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–∏",
    padding="max_length",
    truncation=True,
    return_tensors="pt"
)
```
üí° –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä—å —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ input_ids, attention_mask –∏ token_type_ids, –≥–æ—Ç–æ–≤—ã–π –∫ –ø–æ–¥–∞—á–µ –≤ –º–æ–¥–µ–ª—å.

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
| Epoch | Training Loss | Validation Loss | Accuracy | Macro F1 |
| ----- | ------------- | --------------- | -------- | -------- |
| 1     | 0.0721        | 0.0681          | 0.9838   | 0.9851   |
| 2     | 0.1149        | 0.1396          | 0.9860   | 0.9871   |
| 3     | 0.0586        | 0.1384          | 0.9895   | 0.9903   |

## üíª –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–æ–µ–∫—Ç–æ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ:
1) –û—Ç–∫—Ä—ã—Ç—å –Ω–æ—É—Ç–±—É–∫, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏.
2) –ó–∞–º–µ–Ω–∏—Ç—å –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–≤–æ–∏.
3) –ó–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫–∏ ‚Äî –æ–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è
1) –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π —Å Lenta.ru –∏ –∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
2) –ú–æ–¥–µ–ª—å –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∞—Ç—å –Ω–∞ –¥—Ä—É–≥–∏—Ö –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.
3) –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –Ω–æ—É—Ç–±—É–∫–∞.
